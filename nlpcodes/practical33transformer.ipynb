{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b731532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 08:56:23.388756: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-27 08:56:23.536350: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-27 08:56:23.571150: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-27 08:56:24.196611: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-27 08:56:24.196681: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-27 08:56:24.196689: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f394a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pipeline in module transformers.pipelines:\n",
      "\n",
      "pipeline(task: str = None, model: Optional = None, config: Union[str, transformers.configuration_utils.PretrainedConfig, NoneType] = None, tokenizer: Union[str, transformers.tokenization_utils.PreTrainedTokenizer, NoneType] = None, feature_extractor: Union[str, ForwardRef('SequenceFeatureExtractor'), NoneType] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, use_auth_token: Union[str, bool, NoneType] = None, model_kwargs: Dict[str, Any] = None, pipeline_class: Optional[Any] = None, **kwargs) -> transformers.pipelines.base.Pipeline\n",
      "    Utility factory method to build a [`Pipeline`].\n",
      "    \n",
      "    Pipelines are made of:\n",
      "    \n",
      "        - A [tokenizer](tokenizer) in charge of mapping raw textual input to token.\n",
      "        - A [model](model) to make predictions from the inputs.\n",
      "        - Some (optional) post processing for enhancing model's output.\n",
      "    \n",
      "    Args:\n",
      "        task (`str`):\n",
      "            The task defining which pipeline will be returned. Currently accepted tasks are:\n",
      "    \n",
      "            - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n",
      "            - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n",
      "            - `\"conversational\"`: will return a [`ConversationalPipeline`].\n",
      "            - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n",
      "            - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n",
      "            - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n",
      "            - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n",
      "            - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n",
      "            - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n",
      "            - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n",
      "              [`TextClassificationPipeline`].\n",
      "            - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n",
      "            - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n",
      "            - `\"translation\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"summarization\"`: will return a [`SummarizationPipeline`].\n",
      "            - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n",
      "    \n",
      "        model (`str` or [`PreTrainedModel`] or [`TFPreTrainedModel`], *optional*):\n",
      "            The model that will be used by the pipeline to make predictions. This can be a model identifier or an\n",
      "            actual instance of a pretrained model inheriting from [`PreTrainedModel`] (for PyTorch) or\n",
      "            [`TFPreTrainedModel`] (for TensorFlow).\n",
      "    \n",
      "            If not provided, the default for the `task` will be loaded.\n",
      "        config (`str` or [`PretrainedConfig`], *optional*):\n",
      "            The configuration that will be used by the pipeline to instantiate the model. This can be a model\n",
      "            identifier or an actual pretrained model configuration inheriting from [`PretrainedConfig`].\n",
      "    \n",
      "            If not provided, the default configuration file for the requested model will be used. That means that if\n",
      "            `model` is given, its default configuration will be used. However, if `model` is not supplied, this\n",
      "            `task`'s default model's config is used instead.\n",
      "        tokenizer (`str` or [`PreTrainedTokenizer`], *optional*):\n",
      "            The tokenizer that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained tokenizer inheriting from [`PreTrainedTokenizer`].\n",
      "    \n",
      "            If not provided, the default tokenizer for the given `model` will be loaded (if it is a string). If `model`\n",
      "            is not specified or not a string, then the default tokenizer for `config` is loaded (if it is a string).\n",
      "            However, if `config` is also not given or not a string, then the default tokenizer for the given `task`\n",
      "            will be loaded.\n",
      "        feature_extractor (`str` or [`PreTrainedFeatureExtractor`], *optional*):\n",
      "            The feature extractor that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained feature extractor inheriting from [`PreTrainedFeatureExtractor`].\n",
      "    \n",
      "            Feature extractors are used for non-NLP models, such as Speech or Vision models as well as multi-modal\n",
      "            models. Multi-modal models will also require a tokenizer to be passed.\n",
      "    \n",
      "            If not provided, the default feature extractor for the given `model` will be loaded (if it is a string). If\n",
      "            `model` is not specified or not a string, then the default feature extractor for `config` is loaded (if it\n",
      "            is a string). However, if `config` is also not given or not a string, then the default feature extractor\n",
      "            for the given `task` will be loaded.\n",
      "        framework (`str`, *optional*):\n",
      "            The framework to use, either `\"pt\"` for PyTorch or `\"tf\"` for TensorFlow. The specified framework must be\n",
      "            installed.\n",
      "    \n",
      "            If no framework is specified, will default to the one currently installed. If no framework is specified and\n",
      "            both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is\n",
      "            provided.\n",
      "        revision (`str`, *optional*, defaults to `\"main\"`):\n",
      "            When passing a task name or a string model identifier: The specific model version to use. It can be a\n",
      "            branch name, a tag name, or a commit id, since we use a git-based system for storing models and other\n",
      "            artifacts on huggingface.co, so `revision` can be any identifier allowed by git.\n",
      "        use_fast (`bool`, *optional*, defaults to `True`):\n",
      "            Whether or not to use a Fast tokenizer if possible (a [`PreTrainedTokenizerFast`]).\n",
      "        use_auth_token (`str` or *bool*, *optional*):\n",
      "            The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n",
      "            when running `transformers-cli login` (stored in `~/.huggingface`).\n",
      "        model_kwargs:\n",
      "            Additional dictionary of keyword arguments passed along to the model's `from_pretrained(...,\n",
      "            **model_kwargs)` function.\n",
      "        kwargs:\n",
      "            Additional keyword arguments passed along to the specific pipeline init (see the documentation for the\n",
      "            corresponding pipeline class for possible values).\n",
      "    \n",
      "    Returns:\n",
      "        [`Pipeline`]: A suitable pipeline for the task.\n",
      "    \n",
      "    Examples:\n",
      "    \n",
      "    ```python\n",
      "    >>> from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
      "    \n",
      "    >>> # Sentiment analysis pipeline\n",
      "    >>> pipeline(\"sentiment-analysis\")\n",
      "    \n",
      "    >>> # Question answering pipeline, specifying the checkpoint identifier\n",
      "    >>> pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", tokenizer=\"bert-base-cased\")\n",
      "    \n",
      "    >>> # Named entity recognition pipeline, passing in a specific model and tokenizer\n",
      "    >>> model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
      "    >>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
      "    >>> pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6268df1d",
   "metadata": {},
   "source": [
    "<p><b><u>Importing text-classification transformer from pipeline \n",
    "<p><b><u> model: distilbert-base-uncased-finetuned-sst-2-english\n",
    "<p> can be used for sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceca98b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('text-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee73cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951685e",
   "metadata": {},
   "source": [
    "#### <b><u> Text Input (in list format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6995a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['''Celeste no did call me when she reached North Carolina.''',\n",
    "        '''I was worried because she not drove alone before.''',\n",
    "        '''She was going to meet her friend, Terry, who lived in a town called Asheville, North Carolina.''',\n",
    "        '''I did never want to worry, but she said she was going to call when she reached there.''',\n",
    "        '''Finally, four hours later, she called and said, “Mom, I’m sorry I did not call.''',\n",
    "        '''I lost track of time because I was so happy to see Terry!” I was relieved.''']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042c989c",
   "metadata": {},
   "source": [
    "#### <b><u> Text Input passing from classifier and converting it into dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "699ad364",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64dd0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e1ff4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.969807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.967251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.874502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.991388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.969807\n",
       "1  NEGATIVE  0.967251\n",
       "2  POSITIVE  0.998031\n",
       "3  POSITIVE  0.874502\n",
       "4  NEGATIVE  0.991388\n",
       "5  POSITIVE  0.999238"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaee70c",
   "metadata": {},
   "source": [
    "<b><u> Name Entity Recognition\n",
    "    \n",
    "<b><u> model: dbmdz/bert-large-cased-finetuned-conll03-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f29c08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = '''Celeste no did call me when she reached North Carolina.\n",
    "I was worried because she not drove alone before. \n",
    "She was going to meet her friend, Terry, who lived in a town called Asheville, North Carolina.\n",
    "I did never want to worry, but she said she was going to call when she reached there.\n",
    "Finally, four hours later, she called and said, “Mom, I’m sorry I did not call.\n",
    "I lost track of time because I was so happy to see Terry!” I was relieved.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3140caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384362e93b0840bab8d317a209e0c38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968f998efcfc4c35a601b7bdcd780b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7b0fb27b8a4b8c8a72f34b671e9e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad637661e349417a8d327042d5c1f528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_tag = pipeline('ner', aggregation_strategy = \"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5f80adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ner_tag(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2671894",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1eea58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.991957</td>\n",
       "      <td>Celeste</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>40</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>Terry</td>\n",
       "      <td>141</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>Asheville</td>\n",
       "      <td>175</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>186</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>Terry</td>\n",
       "      <td>419</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score            word  start  end\n",
       "0          PER  0.991957         Celeste      0    7\n",
       "1          LOC  0.999720  North Carolina     40   54\n",
       "2          PER  0.998500           Terry    141  146\n",
       "3          LOC  0.998304       Asheville    175  184\n",
       "4          LOC  0.999516  North Carolina    186  200\n",
       "5          PER  0.997984           Terry    419  424"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7368a979",
   "metadata": {},
   "source": [
    "<p><b><u> question answering transformer\n",
    "<p> model: distilbert-base-cased-distilled-squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66b839bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"“Through my work experience and education, I have developed strong communication skills,\n",
    "and I’m able to clearly convey points to different audiences. \n",
    "I’m also a good listener which aids in my ability to intimately understand a situation and prepare an appropriate response.\n",
    "I believe that my strong organizational skills will also be an asset in this role.”\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2801d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What skills do you have that have prepared you for work in the communications field?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2d10d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    }
   ],
   "source": [
    "qa = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb955bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_qa = qa(question=question,context = review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26d851a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = pd.DataFrame([result_qa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31d3edb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.685133</td>\n",
       "      <td>60</td>\n",
       "      <td>87</td>\n",
       "      <td>strong communication skills</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end                       answer\n",
       "0  0.685133     60   87  strong communication skills"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbb143",
   "metadata": {},
   "source": [
    "<p><b><u> text summarization transformer\n",
    "<p> model: distilbert-base-cased-distilled-squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a250fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "The Indian Space Research Organisation[a] (ISRO; /ˈɪsroʊ/) is the national space agency of India, headquartered in Bengaluru. It operates under the Department of Space (DOS) which is directly overseen by the Prime Minister of India, while the Chairman of ISRO acts as the executive of DOS as well. ISRO is India's primary agency for performing tasks related to space-based applications, space exploration and the development of related technologies.[6] It is one of six government space agencies in the world which possess full launch capabilities, deploy cryogenic engines, launch extraterrestrial missions and operate large fleets of artificial satellites.[7][8][b]\n",
    "\n",
    "The Indian National Committee for Space Research (INCOSPAR) was established by Jawaharlal Nehru under the Department of Atomic Energy (DAE) in 1962, on the urging of scientist Vikram Sarabhai, recognising the need in space research. INCOSPAR grew and became ISRO in 1969, within DAE.[9] In 1972, the government of India set up a Space Commission and DOS, bringing ISRO under it. The establishment of ISRO thus institutionalised space research activities in India.[10][11] It since then has been managed by DOS, which governs various other institutions in India in the domain of astronomy and space technology.[12]\n",
    "\n",
    "ISRO built India's first satellite, Aryabhata, which was launched by the Soviet Union in 1975.[13] In 1980, ISRO launched satellite RS-1 onboard its own SLV-3, making India the seventh country to be capable of undertaking orbital launches. SLV-3 was followed by ASLV, which was subsequently succeeded by development of many medium-lift launch vehicles, rocket engines, satellite systems and networks enabling the agency to launch hundreds of domestic and foreign satellites and various deep space missions for space exploration.\n",
    "\n",
    "ISRO has the world's largest constellation of remote-sensing satellites and operates the GAGAN and NAVIC satellite navigation systems. It has sent two missions to the Moon and one to Mars.\n",
    "\n",
    "Goals in near future include expanding satellites fleet, landing a rover on Moon, sending humans into space, development of a semi-cryogenic engine, sending more unmanned missions to the Moon, Mars, Venus and Sun and deployment of more space telescopes in orbit to observe cosmic phenomena and outerspace beyond the Solar System. Long-term plans include development of reusable launchers, heavy and super heavy launch vehicles, deploying a space station, sending exploration missions to external planets like Jupiter, Uranus, Neptune and asteroids and manned missions to moons and planets.\n",
    "\n",
    "ISRO's programs have played a significant role in the socio-economic development of India and have supported both civilian and military domains in various aspects including disaster management, telemedicine and navigation and reconnaissance missions. ISRO's spin off technologies also have founded many crucial innovations for India's engineering and medical industries.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "550fb8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84df0ed8fe494ccab2ee9401627331c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b1c716696347959d9473dbcd1fee7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88603951eb44aa0b1a45fd4a2f5f66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354a9dda5587411bb7c13249a9957228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91548b761d914665b85b80ecdaf91538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_summarizer = pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ac39c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ts = text_summarizer(text,\n",
    "                           max_length = 100,\n",
    "                           clean_up_tokenization_spaces = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3d3fe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Indian Space Research Organisation (ISRO) is the national space agency of India. It is one of six government space agencies in the world which possess full launch capabilities, deploy cryogenic engines, launch extraterrestrial missions and operate large fleets of artificial satellites. ISRO has the world's largest constellation of remote-sensing satellites and operates the GAGAN and NAVIC satellite navigation systems.\n"
     ]
    }
   ],
   "source": [
    "print(result_ts[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21727e33",
   "metadata": {},
   "source": [
    "<p><b><u> translation transformer\n",
    "<p> model: t5-base (Language(s) (NLP): English, French, Romanian, German)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3343a51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base (https://huggingface.co/t5-base)\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline('translation_en_to_fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f89110ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am fine, Thank You...!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66ef312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_translate = translator(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00a11997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Je suis bien, Merci...!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            translation_text\n",
       "0  Je suis bien, Merci...!!!"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result_translate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2d591",
   "metadata": {},
   "source": [
    "How are you? ---> Comment vous êtes-vous?\n",
    "(Comment ca va?) ---> (How did you do?)\n",
    "\n",
    "\n",
    "I am fine, Thank You...!!! ---> Je suis bien, Merci...!!!\n",
    "(Je vais bien merci...!!!) ---> (I am well thank you...!!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c38acc",
   "metadata": {},
   "source": [
    "<p><b><u> conversation transformer\n",
    "<p> model: microsoft/DialoGPT-medium (https://huggingface.co/microsoft/DialoGPT-medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1509c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0936c967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to microsoft/DialoGPT-medium (https://huggingface.co/microsoft/DialoGPT-medium)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a905471db04bb5a28bdc3ef486fb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a29dab492284c71b46a780386052fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/823M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4b5fb8d7534ab4b00ce13f72013eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6fd76e3e78463ea3ec0036af1e4d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938b8334a0824ba9a63e71069539e583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv = pipeline('conversational')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e3afb4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "conver = Conversation(\"What is national flower of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a9aa58f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "conver = conv(conver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c96b226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I think it's a flower that's not a national flower.\"]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conver.generated_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111df101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7c1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
